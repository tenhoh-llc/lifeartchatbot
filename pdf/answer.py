"""
è³ªå•ã«å¯¾ã™ã‚‹ç›´æ¥çš„ãªå›ç­”ã‚’ç”Ÿæˆã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
æŠœç²‹ã‹ã‚‰è¦ç‚¹ã‚’æŠ½å‡ºã—ã¦ã€ã‚ã‹ã‚Šã‚„ã™ã„å›ç­”ã‚’ä½œæˆ
"""
from typing import List, Optional
from pdf.search import SearchHit
from pdf.snippet import Snippet


def generate_answer(query: str, hits: List[SearchHit], snippet: Snippet, context: str = None) -> str:
    """
    æ¤œç´¢çµæœã‹ã‚‰è³ªå•ã«å¯¾ã™ã‚‹ç›´æ¥çš„ãªå›ç­”ã‚’ç”Ÿæˆ
    
    Args:
        query: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•
        hits: æ¤œç´¢çµæœ
        snippet: æŠœç²‹
        context: å‰ã®ä¼šè©±ã®æ–‡è„ˆ
    
    Returns:
        ã‚ã‹ã‚Šã‚„ã™ã„å›ç­”æ–‡
    """
    if not hits:
        return "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚è©²å½“ã™ã‚‹æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
    
    best_hit = hits[0]
    text = best_hit.text.lower()
    query_lower = query.lower()
    
    # æ–‡è„ˆã‚’è€ƒæ…®ã—ãŸå›ç­”ã®åˆ¤å®š
    is_negative_query = any(word in query_lower for word in ["å–ã‚Œãªã„", "ã§ããªã„", "å¯¾è±¡å¤–", "é™¤å¤–", "ä¾‹å¤–", "ä¸å¯"])
    is_condition_query = any(word in query_lower for word in ["æ¡ä»¶", "è¦ä»¶", "è³‡æ ¼", "å¯¾è±¡"])
    
    # è‚²å…ä¼‘æ¥­ã®æ–‡è„ˆã‹ã©ã†ã‹
    is_ikuji_context = context and "è‚²" in context
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®å›ç­”ç”Ÿæˆ
    answers = []
    
    # æ™‚é–“å¤–å‹¤å‹™ãƒ»æ®‹æ¥­
    if any(word in query_lower for word in ["æ™‚é–“å¤–", "æ®‹æ¥­", "overtime"]):
        if "æ™‚é–“å¤–å‹¤å‹™" in text or "æ®‹æ¥­" in text:
            # ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ•°å€¤ã‚’æŠ½å‡º
            import re
            monthly = re.search(r'æœˆ(\d+)æ™‚é–“', best_hit.text)
            yearly = re.search(r'å¹´(\d+)æ™‚é–“', best_hit.text)
            
            if monthly and yearly:
                answers.append(f"ğŸ“‹ **æ™‚é–“å¤–å‹¤å‹™ã®ä¸Šé™**")
                answers.append(f"â€¢ æœˆé–“ä¸Šé™: {monthly.group(1)}æ™‚é–“")
                answers.append(f"â€¢ å¹´é–“ä¸Šé™: {yearly.group(1)}æ™‚é–“")
                answers.append(f"â€¢ ç‰¹åˆ¥ãªäº‹æƒ…ãŒã‚ã‚‹å ´åˆã¯åŠ´ä½¿å”å®šã«ã‚ˆã‚Šå»¶é•·å¯èƒ½ã§ã™")
    
    # æœ‰çµ¦ä¼‘æš‡
    elif any(word in query_lower for word in ["æœ‰çµ¦", "æœ‰ä¼‘", "å¹´ä¼‘"]):
        if "æœ‰çµ¦" in text or "æœ‰ä¼‘" in text:
            import re
            days = re.search(r'å¹´é–“(\d+)æ—¥', best_hit.text)
            max_days = re.search(r'æœ€å¤§(\d+)æ—¥', best_hit.text)
            
            if days:
                answers.append(f"ğŸ–ï¸ **æœ‰çµ¦ä¼‘æš‡ã«ã¤ã„ã¦**")
                answers.append(f"â€¢ å¹´é–“ä»˜ä¸æ—¥æ•°: {days.group(1)}æ—¥")
                if max_days:
                    answers.append(f"â€¢ æœ€å¤§ä¿æœ‰æ—¥æ•°: {max_days.group(1)}æ—¥ï¼ˆç¹°è¶Šå«ã‚€ï¼‰")
                answers.append(f"â€¢ ç¿Œå¹´åº¦ã¸ã®ç¹°è¶ŠãŒå¯èƒ½ã§ã™")
    
    # çµ¦ä¸ãƒ»çµ¦æ–™
    elif any(word in query_lower for word in ["çµ¦ä¸", "çµ¦æ–™", "è³ƒé‡‘", "æ”¯æ‰•"]):
        if "çµ¦ä¸" in text or "çµ¦æ–™" in text:
            import re
            closing = re.search(r'ç· æ—¥.*?(\d+)æ—¥', best_hit.text)
            payment = re.search(r'æ”¯æ‰•.*?(\d+)æ—¥', best_hit.text)
            
            if closing or payment:
                answers.append(f"ğŸ’° **çµ¦ä¸æ”¯æ‰•ã«ã¤ã„ã¦**")
                if closing:
                    answers.append(f"â€¢ ç· æ—¥: æ¯æœˆ{closing.group(1)}æ—¥")
                if payment:
                    answers.append(f"â€¢ æ”¯æ‰•æ—¥: ç¿Œæœˆ{payment.group(1)}æ—¥")
                answers.append(f"â€¢ æ”¯æ‰•æ—¥ãŒä¼‘æ—¥ã®å ´åˆã¯å‰å–¶æ¥­æ—¥ã«æ”¯æ‰•")
    
    # è‚²å…ä¼‘æ¥­é–¢é€£ã®è³ªå•ã‚’è©³ç´°ã«å‡¦ç†
    elif any(word in query_lower for word in ["è‚²å…", "è‚²ä¼‘", "ç”£ä¼‘"]) or is_ikuji_context:
        # å¦å®šçš„ãªè³ªå•ï¼ˆå–ã‚Œãªã„äººã€å¯¾è±¡å¤–ãªã©ï¼‰
        if is_negative_query or "å¯¾è±¡å¤–" in text or "é™¤å¤–" in text:
            # ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å¯¾è±¡å¤–æ¡ä»¶ã‚’æ¢ã™
            import re
            exclusions = []
            
            # ã‚ˆãã‚ã‚‹é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¢ã™
            if "é›‡ç”¨æœŸé–“" in text or "ï¼‘å¹´æœªæº€" in text:
                exclusions.append("â€¢ é›‡ç”¨æœŸé–“ãŒ1å¹´æœªæº€ã®å¾“æ¥­å“¡")
            if "æœ‰æœŸé›‡ç”¨" in text or "æœŸé–“" in text:
                exclusions.append("â€¢ æœ‰æœŸé›‡ç”¨ã§å¥‘ç´„æœŸé–“ãŒé™å®šã•ã‚Œã¦ã„ã‚‹å ´åˆ")
            if "æ—¥ã€…é›‡ç”¨" in text:
                exclusions.append("â€¢ æ—¥ã€…é›‡ç”¨ã®å¾“æ¥­å“¡")
            if "é€±" in text and ("ï¼’æ—¥" in text or "3æ—¥" in text):
                exclusions.append("â€¢ é€±ã®æ‰€å®šåŠ´åƒæ—¥æ•°ãŒ2æ—¥ä»¥ä¸‹ã®å¾“æ¥­å“¡")
            
            if exclusions:
                answers.append(f"ğŸš« **è‚²å…ä¼‘æ¥­ã‚’å–å¾—ã§ããªã„å ´åˆ**")
                answers.extend(exclusions)
                answers.append("â€» è©³ç´°ã¯è‚²å…ä»‹è­·ä¼‘æ¥­è¦ç¨‹ã‚’ã”ç¢ºèªãã ã•ã„")
            else:
                # ä¸€èˆ¬çš„ãªé™¤å¤–æ¡ä»¶ã‚’æç¤º
                answers.append(f"ğŸš« **ä¸€èˆ¬çš„ã«è‚²å…ä¼‘æ¥­ã‚’å–å¾—ã§ããªã„å ´åˆ**")
                answers.append(f"â€¢ é›‡ç”¨æœŸé–“ãŒ1å¹´æœªæº€")
                answers.append(f"â€¢ 1å¹´ä»¥å†…ã«é›‡ç”¨é–¢ä¿‚ãŒçµ‚äº†ã™ã‚‹äºˆå®š")
                answers.append(f"â€¢ é€±ã®æ‰€å®šåŠ´åƒæ—¥æ•°ãŒ2æ—¥ä»¥ä¸‹")
                answers.append(f"â€» æ­£ç¢ºãªæ¡ä»¶ã¯è‚²å…ä»‹è­·ä¼‘æ¥­è¦ç¨‹ã‚’ã”ç¢ºèªãã ã•ã„")
        else:
            # é€šå¸¸ã®è‚²å…ä¼‘æ¥­ã®èª¬æ˜
            answers.append(f"ğŸ‘¶ **è‚²å…ä¼‘æ¥­ã«ã¤ã„ã¦**")
            answers.append(f"â€¢ åŸºæœ¬æœŸé–“: å­ãŒ1æ­³ã«é”ã™ã‚‹ã¾ã§")
            answers.append(f"â€¢ å»¶é•·å¯èƒ½: æœ€å¤§2æ­³ã¾ã§ï¼ˆä¿è‚²åœ’ã«å…¥ã‚Œãªã„ç­‰ã®äº‹æƒ…ãŒã‚ã‚‹å ´åˆï¼‰")
            answers.append(f"â€¢ ç”³è«‹ã¯äººäº‹éƒ¨ã¾ã§")
    
    # æ™‚çŸ­å‹¤å‹™
    elif any(word in query_lower for word in ["æ™‚çŸ­", "çŸ­æ™‚é–“", "æ™‚é–“çŸ­ç¸®"]):
        if "æ™‚çŸ­" in text or "çŸ­æ™‚é–“" in text:
            answers.append(f"â° **æ™‚çŸ­å‹¤å‹™åˆ¶åº¦**")
            answers.append(f"â€¢ å¯¾è±¡: 3æ­³æœªæº€ã®å­ã‚’é¤Šè‚²ã™ã‚‹ç¤¾å“¡")
            answers.append(f"â€¢ å‹¤å‹™æ™‚é–“: 1æ—¥6æ™‚é–“")
            answers.append(f"â€¢ ç”³è«‹ã¯ä¸Šé•·ã¨äººäº‹éƒ¨ã¸")
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå›ç­”
    if not answers:
        # æŠœç²‹ã‹ã‚‰æœ€åˆã®1æ–‡ã‚’å–å¾—
        first_sentence = best_hit.text.split("ã€‚")[0] if "ã€‚" in best_hit.text else best_hit.text[:100]
        answers.append(f"ğŸ“„ **é–¢é€£æƒ…å ±**")
        answers.append(first_sentence + "ã€‚")
    
    return "\n".join(answers)


def format_full_answer(
    query: str,
    answer: str,
    snippet: Snippet,
    source: SearchHit
) -> dict:
    """
    å®Œå…¨ãªå›ç­”ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    
    Returns:
        dict: å›ç­”ã€æ ¹æ‹ ã€å‡ºå…¸ã‚’å«ã‚€è¾æ›¸
    """
    return {
        "answer": answer,
        "evidence": snippet.excerpt,
        "source": {
            "file": source.file_name,
            "page": source.page_no,
            "section": source.section,
            "score": source.score
        },
        "disclaimer": "â€» ã“ã®å›ç­”ã¯è¦ç¨‹æ–‡æ›¸ã‹ã‚‰ã®æŠœç²‹ã«åŸºã¥ã„ã¦ã„ã¾ã™ã€‚æ­£å¼ãªç¢ºèªã¯åŸæœ¬ã‚’ã”å‚ç…§ãã ã•ã„ã€‚"
    }


def generate_qa_style_response(query: str, hits: List[SearchHit]) -> str:
    """
    Q&Aå½¢å¼ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆ
    
    Args:
        query: è³ªå•
        hits: æ¤œç´¢çµæœ
    
    Returns:
        Q&Aå½¢å¼ã®å›ç­”
    """
    if not hits:
        return "è©²å½“ã™ã‚‹æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚åˆ¥ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ãŠè©¦ã—ãã ã•ã„ã€‚"
    
    response = []
    response.append(f"**Q: {query}**\n")
    
    # ãƒ¡ã‚¤ãƒ³å›ç­”
    answer = generate_answer(query, hits, None)
    response.append(f"**A:** {answer}\n")
    
    # é–¢é€£æƒ…å ±
    if len(hits) > 1:
        response.append("\n**ğŸ“š é–¢é€£ã™ã‚‹è¦ç¨‹:**")
        for i, hit in enumerate(hits[:3], 1):
            if hit.section:
                response.append(f"{i}. {hit.section} ({hit.file_name} p.{hit.page_no})")
    
    return "\n".join(response)